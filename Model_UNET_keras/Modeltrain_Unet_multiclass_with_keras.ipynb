{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: tensorflow in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.16.1)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.2.1)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.4.1.post1)\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (3.8.3)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /Users/quentinlandon/Library/Python/3.12/lib/python/site-packages (from tensorflow) (24.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (69.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/quentinlandon/Library/Python/3.12/lib/python/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (4.10.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (1.62.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/quentinlandon/Library/Python/3.12/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (1.12.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (3.4.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (4.50.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow) (0.0.7)\n",
      "Requirement already satisfied: optree in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/quentinlandon/Library/Python/3.12/lib/python/site-packages (from rich->keras>=3.0.0->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy tensorflow pandas scikit-learn matplotlib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tkinter import Tk, filedialog\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, concatenate\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 19s/step - accuracy: 0.3936 - loss: 32.0322 - val_accuracy: 0.5147 - val_loss: 1.0388\n",
      "Epoch 2/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 18s/step - accuracy: 0.5455 - loss: 1.0734 - val_accuracy: 0.4860 - val_loss: 0.9294\n",
      "Epoch 3/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 16s/step - accuracy: 0.5715 - loss: 0.9001 - val_accuracy: 0.5405 - val_loss: 0.5996\n",
      "Epoch 4/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 16s/step - accuracy: 0.5731 - loss: 0.6638 - val_accuracy: 0.6774 - val_loss: 0.5915\n",
      "Epoch 5/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 17s/step - accuracy: 0.6321 - loss: 0.6256 - val_accuracy: 0.8001 - val_loss: 0.4442\n",
      "Epoch 6/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 17s/step - accuracy: 0.7301 - loss: 0.5249 - val_accuracy: 0.7418 - val_loss: 0.5543\n",
      "Epoch 7/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 16s/step - accuracy: 0.6877 - loss: 0.6605 - val_accuracy: 0.8330 - val_loss: 0.3564\n",
      "Epoch 8/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 16s/step - accuracy: 0.7717 - loss: 0.4731 - val_accuracy: 0.6600 - val_loss: 0.5133\n",
      "Epoch 9/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 16s/step - accuracy: 0.7507 - loss: 0.5060 - val_accuracy: 0.8499 - val_loss: 0.3269\n",
      "Epoch 10/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 16s/step - accuracy: 0.8221 - loss: 0.3997 - val_accuracy: 0.8797 - val_loss: 0.3248\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x17eb454c0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chargement du fichier CSV\n",
    "df = pd.read_csv('/Users/quentinlandon/Desktop/GIT_Projet_theo/APP_IA_TL_QL_dev/informations_masques.csv')\n",
    "\n",
    "# Extraction des chemins des images brutes et des masques\n",
    "images_paths = df['pathimg'].values\n",
    "masks_paths = df['pathmask'].values\n",
    "\n",
    "# Fonction pour charger les images et les masques\n",
    "def load_images_and_masks(images_paths, masks_paths):\n",
    "    images = []\n",
    "    masks = []\n",
    "    for img_path, mask_path in zip(images_paths, masks_paths):\n",
    "        img = load_img(img_path, target_size=(256, 256))\n",
    "        mask = load_img(mask_path, target_size=(256, 256), color_mode='grayscale')\n",
    "        images.append(img_to_array(img))\n",
    "        masks.append(img_to_array(mask))\n",
    "    return np.array(images), np.array(masks)\n",
    "\n",
    "# Chargement des images et des masques\n",
    "images, masks = load_images_and_masks(images_paths, masks_paths)\n",
    "\n",
    "# Division des données en ensembles d'entraînement et de test (80% pour l'entraînement, 20% pour le test)\n",
    "x_train, x_test, y_train, y_test = train_test_split(images, masks, test_size=0.2, random_state=42)\n",
    "\n",
    "# Définir input_shape\n",
    "input_shape = (256, 256, 3)  # Taille de l'image : 256x256 pixels, 3 canaux (RGB)\n",
    "\n",
    "# Modifier la couche de sortie pour gérer les classes multiples\n",
    "def unet_multiclass(input_shape, num_classes):\n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    # Chemin contractant\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    # Fond\n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(conv3)\n",
    "\n",
    "    # Chemin expansif\n",
    "    up4 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv3)\n",
    "    up4 = concatenate([up4, conv2], axis=3)\n",
    "    conv4 = Conv2D(128, 3, activation='relu', padding='same')(up4)\n",
    "    conv4 = Conv2D(128, 3, activation='relu', padding='same')(conv4)\n",
    "\n",
    "    up5 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv4)\n",
    "    up5 = concatenate([up5, conv1], axis=3)\n",
    "    conv5 = Conv2D(64, 3, activation='relu', padding='same')(up5)\n",
    "    conv5 = Conv2D(64, 3, activation='relu', padding='same')(conv5)\n",
    "\n",
    "    # Couche de sortie pour les classes multiples avec softmax\n",
    "    outputs = Conv2D(num_classes, 1, activation='softmax')(conv5)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model\n",
    "\n",
    "# Déterminer le nombre de classes à partir des masques d'entraînement\n",
    "num_classes = np.max([len(np.unique(mask)) for mask in y_train])\n",
    "\n",
    "# Création du modèle U-Net pour plusieurs classes\n",
    "model = unet_multiclass(input_shape, num_classes)\n",
    "\n",
    "# Compilation du modèle avec la perte et l'optimiseur appropriés\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Limiter les valeurs de pixel dans les masques à un nombre de classes maximum\n",
    "def limit_mask_classes(mask, num_classes):\n",
    "    return np.where(mask < num_classes, mask, num_classes - 1)\n",
    "\n",
    "# Appliquer la fonction de seuillage aux masques d'entraînement et de test\n",
    "y_train_limited = np.array([limit_mask_classes(mask, num_classes) for mask in y_train])\n",
    "y_test_limited = np.array([limit_mask_classes(mask, num_classes) for mask in y_test])\n",
    "\n",
    "# Encodage one-hot des masques\n",
    "y_train_encoded = to_categorical(y_train_limited, num_classes=max(num_classes, num_classes))\n",
    "y_test_encoded = to_categorical(y_test_limited, num_classes=max(num_classes, num_classes))\n",
    "\n",
    "# Entraînement du modèle\n",
    "model.fit(x_train, y_train_encoded, batch_size=32, epochs=10, validation_data=(x_test, y_test_encoded))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (1931783072.py, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[5], line 18\u001b[0;36m\u001b[0m\n\u001b[0;31m    recall = recall_score(tr   ue_class.flatten(), predicted_class.flatten(), average='weighted')\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "def visualize_result(model, option, image_path=None, image=None, true_mask=None):\n",
    "    if option == 0:\n",
    "        # Visualisation des résultats sur des données déjà labellisées\n",
    "        # Prédiction du masque avec le modèle\n",
    "        predicted_mask = model.predict(np.expand_dims(image, axis=0))[0]\n",
    "        \n",
    "        # Convertir les masques prédits et vrais en classes (0, 1, 2, ...)\n",
    "        predicted_class = np.argmax(predicted_mask, axis=-1)\n",
    "        true_class = np.argmax(true_mask, axis=-1)\n",
    "        \n",
    "        # Calculer les scores de précision, rappel et F-mesure\n",
    "        precision = precision_score(true_class.flatten(), predicted_class.flatten(), average='weighted')\n",
    "        recall = recall_score(tr   ue_class.flatten(), predicted_class.flatten(), average='weighted')\n",
    "        f1 = f1_score(true_class.flatten(), predicted_class.flatten(), average='weighted')\n",
    "        \n",
    "        # Afficher les scores\n",
    "        print(\"Precision:\", precision)\n",
    "        print(\"Recall:\", recall)\n",
    "        print(\"F1 Score:\", f1)\n",
    "        \n",
    "        # Afficher l'image\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(image)\n",
    "        plt.title(\"Image\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Afficher le masque prédit\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(predicted_class, cmap='viridis', vmin=0, vmax=np.max(predicted_class))\n",
    "        plt.title(\"Predicted Mask\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Afficher le masque vrai\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(true_class, cmap='viridis', vmin=0, vmax=np.max(true_class))\n",
    "        plt.title(\"True Mask\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "    elif option == 1:\n",
    "        # Visualisation des résultats sur une image brute non labellisée\n",
    "        # Charger l'image\n",
    "        image = load_img(image_path, target_size=(256, 256))\n",
    "        image_array = img_to_array(image)\n",
    "        \n",
    "        # Prédiction du masque avec le modèle\n",
    "        predicted_mask = model.predict(np.expand_dims(image_array, axis=0))[0]\n",
    "        \n",
    "        # Convertir le masque prédit en classes (0, 1, 2, ...)\n",
    "        predicted_class = np.argmax(predicted_mask, axis=-1)\n",
    "        \n",
    "        # Afficher l'image et le masque prédit\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(image)\n",
    "        plt.title(\"Image\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(predicted_class, cmap='viridis', vmin=0, vmax=np.max(predicted_class))\n",
    "        plt.title(\"Predicted Mask\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "# Utilisation de la fonction pour visualiser les résultats\n",
    "option = int(input(\"Choisissez l'option (0: Données labellisées, 1: Image brute non labellisée): \"))\n",
    "\n",
    "if option == 0:\n",
    "    index = int(input(\"Entrez l'indice de l'image à visualiser : \"))\n",
    "    visualize_result(model, option, image=x_test[index], true_mask=y_test_encoded[index])\n",
    "elif option == 1:\n",
    "    image_path = input(\"Entrez le chemin de l'image à visualiser : \")\n",
    "    visualize_result(model, option, image_path=image_path)\n",
    "else:\n",
    "    print(\"Option invalide.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
